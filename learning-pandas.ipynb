{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.read_csv(\"data/daily_report.csv\")\n",
    "temp = pd.read_csv(\"data/daily_report.csv\")\n",
    "# 쥬피터에 의해서 불려진 csv파일은 자동적으로 표가 된다. 이 표 안에서 내가 활용하고 싶은 데이터를 골라서 따로 표시가능한데\n",
    "# 그건 리스트의 형식과 동일하다. 단, 구분은 컬럼(열)으로 하며 [[...]] 이중 괄호를 사용하여 분리한다.\n",
    "# sum()함수를 사용하여 로우(행)의 합계를 낼수 있다.\n",
    "# 단, 이때에는 데이터 형식이 데이터 프레임에서 시리즈라는 형식으로 바뀌기 때문에, 다시 그 형식을 표로 바꿔줄 필요가 있다.l\n",
    "# 따라서 reset_index()를 이용하여 표로 전환해준다.\n",
    "# 이 과정에서 컬럼의 이름을 바꾸는 것도 가능하다. reset_index() 내부에 인수name의 밸류값으로 문자열을 지정하면 컬럼 명이 바뀐다.\n",
    "# 컬럼의 명을 바꾸는 명령어는 rename()이며 인수값으로 이름을 전달하면 컬럼 값을 바꿀수 있다. \n",
    "totals_df = daily_df[[\"Country_Region\",\"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "group_df = totals_df.groupby(\"Country_Region\")\n",
    "group_df.sum().reset_index()\n",
    "# series와 dataframe의 차이점은 뭐지??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continent-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 판다스는 주로 csv를 컨트롤 하게 해준다.l\n",
    "# 만다스를 임포트 하여서 csv형식의 데이터 파일을 읽어들인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "suspended-chicken",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>557</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>655</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>941</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>1433</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>2118</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2/25/21</td>\n",
       "      <td>113001412</td>\n",
       "      <td>2507630</td>\n",
       "      <td>63732290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2/26/21</td>\n",
       "      <td>113444373</td>\n",
       "      <td>2517957</td>\n",
       "      <td>63992558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>2/27/21</td>\n",
       "      <td>113833159</td>\n",
       "      <td>2526118</td>\n",
       "      <td>64243283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>2/28/21</td>\n",
       "      <td>114136355</td>\n",
       "      <td>2531555</td>\n",
       "      <td>64418459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>3/1/21</td>\n",
       "      <td>114428987</td>\n",
       "      <td>2538582</td>\n",
       "      <td>64620915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  confirmed   deaths  recovered\n",
       "0    1/22/20        557       17         30\n",
       "1    1/23/20        655       18         32\n",
       "2    1/24/20        941       26         39\n",
       "3    1/25/20       1433       42         42\n",
       "4    1/26/20       2118       56         56\n",
       "..       ...        ...      ...        ...\n",
       "400  2/25/21  113001412  2507630   63732290\n",
       "401  2/26/21  113444373  2517957   63992558\n",
       "402  2/27/21  113833159  2526118   64243283\n",
       "403  2/28/21  114136355  2531555   64418459\n",
       "404   3/1/21  114428987  2538582   64620915\n",
       "\n",
       "[405 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conditions = [\"confirmed\", \"deaths\", \"recovered\"]\n",
    "\n",
    "def make_global_df(condition):\n",
    "    df = pd.read_csv(f\"data/time_{condition}.csv\")\n",
    "    df = df.drop(['Province/State', 'Country/Region', 'Lat', 'Long'], axis=1).sum().reset_index(name=condition)\n",
    "    df = df.rename(columns={\"index\":\"Date\"})\n",
    "    return df\n",
    "\n",
    "final_df = None\n",
    "for condition in conditions:\n",
    "    condition_df = make_global_df(condition)\n",
    "   # result = pd.concat([result, condition_df], axis=1, join=\"outer\")\n",
    "    if final_df is None:\n",
    "        final_df = condition_df\n",
    "    else:\n",
    "       # result = pd.concat([result, condition_df], ignore_index=True, sort=False)\n",
    "        final_df = result.merge(condition_df)\n",
    "\n",
    "result   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
